"use strict";(self.webpackChunksuperbench_website=self.webpackChunksuperbench_website||[]).push([[1100],{5680:(e,n,r)=>{r.d(n,{xA:()=>u,yg:()=>h});var t=r(6540);function o(e,n,r){return n in e?Object.defineProperty(e,n,{value:r,enumerable:!0,configurable:!0,writable:!0}):e[n]=r,e}function a(e,n){var r=Object.keys(e);if(Object.getOwnPropertySymbols){var t=Object.getOwnPropertySymbols(e);n&&(t=t.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),r.push.apply(r,t)}return r}function i(e){for(var n=1;n<arguments.length;n++){var r=null!=arguments[n]?arguments[n]:{};n%2?a(Object(r),!0).forEach((function(n){o(e,n,r[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(r)):a(Object(r)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(r,n))}))}return e}function c(e,n){if(null==e)return{};var r,t,o=function(e,n){if(null==e)return{};var r,t,o={},a=Object.keys(e);for(t=0;t<a.length;t++)r=a[t],n.indexOf(r)>=0||(o[r]=e[r]);return o}(e,n);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);for(t=0;t<a.length;t++)r=a[t],n.indexOf(r)>=0||Object.prototype.propertyIsEnumerable.call(e,r)&&(o[r]=e[r])}return o}var s=t.createContext({}),l=function(e){var n=t.useContext(s),r=n;return e&&(r="function"==typeof e?e(n):i(i({},n),e)),r},u=function(e){var n=l(e.components);return t.createElement(s.Provider,{value:n},e.children)},p={inlineCode:"code",wrapper:function(e){var n=e.children;return t.createElement(t.Fragment,{},n)}},d=t.forwardRef((function(e,n){var r=e.components,o=e.mdxType,a=e.originalType,s=e.parentName,u=c(e,["components","mdxType","originalType","parentName"]),d=l(r),h=o,m=d["".concat(s,".").concat(h)]||d[h]||p[h]||a;return r?t.createElement(m,i(i({ref:n},u),{},{components:r})):t.createElement(m,i({ref:n},u))}));function h(e,n){var r=arguments,o=n&&n.mdxType;if("string"==typeof e||o){var a=r.length,i=new Array(a);i[0]=d;var c={};for(var s in n)hasOwnProperty.call(n,s)&&(c[s]=n[s]);c.originalType=e,c.mdxType="string"==typeof e?e:o,i[1]=c;for(var l=2;l<a;l++)i[l]=r[l];return t.createElement.apply(null,i)}return t.createElement.apply(null,r)}d.displayName="MDXCreateElement"},6261:(e,n,r)=>{r.r(n),r.d(n,{contentTitle:()=>s,default:()=>d,frontMatter:()=>c,metadata:()=>l,toc:()=>u});var t=r(8168),o=r(8587),a=(r(6540),r(5680)),i=["components"],c={id:"overview"},s="Superbench Design",l={unversionedId:"design-docs/overview",id:"design-docs/overview",isDocsHomePage:!1,title:"Superbench Design",description:"Goals",source:"@site/../docs/design-docs/overview.md",sourceDirName:"design-docs",slug:"/design-docs/overview",permalink:"/superbenchmark/docs/design-docs/overview",editUrl:"https://github.com/microsoft/superbenchmark/edit/main/website/../docs/design-docs/overview.md",version:"current",frontMatter:{id:"overview"},sidebar:"docs",previous:{title:"Contributing",permalink:"/superbenchmark/docs/developer-guides/contributing"},next:{title:"Benchmarks Design",permalink:"/superbenchmark/docs/design-docs/benchmarks"}},u=[{value:"Goals",id:"goals",children:[]},{value:"Architecture",id:"architecture",children:[]},{value:"Pipeline",id:"pipeline",children:[]},{value:"Components",id:"components",children:[{value:"SuperBench CLI",id:"superbench-cli",children:[]},{value:"SuperBench Runner",id:"superbench-runner",children:[]},{value:"SuperBench Executor",id:"superbench-executor",children:[]},{value:"Benchmarks",id:"benchmarks",children:[]}]}],p={toc:u};function d(e){var n=e.components,c=(0,o.A)(e,i);return(0,a.yg)("wrapper",(0,t.A)({},p,c,{components:n,mdxType:"MDXLayout"}),(0,a.yg)("h1",{id:"superbench-design"},"Superbench Design"),(0,a.yg)("h2",{id:"goals"},"Goals"),(0,a.yg)("p",null,"SuperBench targets on providing a distribution test in cluster with 100 ~ 1000 nodes,\nand making it modulable, easy to use and easy to scale up.\nTherefore, SuperBench would like to provide a more simple and convenient way to:"),(0,a.yg)("ol",null,(0,a.yg)("li",{parentName:"ol"},"Install and deploy SuperBench in a raw cluster, including bare-metal, on-premises, and cloud environments."),(0,a.yg)("li",{parentName:"ol"},"Configure SuperBench configurations, by specifying config file or using command line arguments."),(0,a.yg)("li",{parentName:"ol"},"Execute the command locally to launch SuperBench on selected devices/nodes or on all nodes in the cluster. Use single device, selected devices, or all devices, including GPU and InfiniBand."),(0,a.yg)("li",{parentName:"ol"},"Support distributed benchmarks in SuperBench, including NCCL tests using MPI, model performance tests using torch distributed, etc."),(0,a.yg)("li",{parentName:"ol"},"Collect log during running, save results after running, and merge all nodes' results to one summary report."),(0,a.yg)("li",{parentName:"ol"},"Provide a unified interface for all benchmarks, including how to run on different device vendor (NVIDIA/AMD), how to run on different mode (local/mpi), how to pass configurations and save results.")),(0,a.yg)("h2",{id:"architecture"},"Architecture"),(0,a.yg)("p",null,(0,a.yg)("img",{alt:"SuperBench Workflow",src:r(7168).A})),(0,a.yg)("h2",{id:"pipeline"},"Pipeline"),(0,a.yg)("p",null,(0,a.yg)("img",{alt:"Pipeline",src:r(2183).A})),(0,a.yg)("ol",null,(0,a.yg)("li",{parentName:"ol"},"User prepares config file and host file. Both files can be omitted by using the default config or command line arguments to specify."),(0,a.yg)("li",{parentName:"ol"},"User runs SuperBench CLI on head node. Command line interface could accept a set of arguments and provide help information to user."),(0,a.yg)("li",{parentName:"ol"},"SuperBench CLI parses the input config file, host file, and arguments, loads into one config object, and calls SuperBench Runner to start the test."),(0,a.yg)("li",{parentName:"ol"},"SuperBench Runner parses the config and execute following steps on all nodes specified in config,",(0,a.yg)("ol",{parentName:"li"},(0,a.yg)("li",{parentName:"ol"},"Check the connection."),(0,a.yg)("li",{parentName:"ol"},"Check docker environment and SuperBench Docker image."),(0,a.yg)("li",{parentName:"ol"},"Start a SuperBench Docker container, and mount necessary paths."),(0,a.yg)("li",{parentName:"ol"},"Prepare running context, including local package code, config file, SSH key pairs, SSH config for passwordless use, and distribute to all nodes."),(0,a.yg)("li",{parentName:"ol"},"Prepare output path."),(0,a.yg)("li",{parentName:"ol"},"Start SSH service and check inter-connections."))),(0,a.yg)("li",{parentName:"ol"},"SuperBench Runner  loops all benchmarks and all modes in each benchmark. For each mode in each benchmark, SuperBench Runner calls SuperBench Executor inside Docker container on corresponding nodes to start an execution."),(0,a.yg)("li",{parentName:"ol"},"SuperBench Executor parses the config object, start benchmarks inside Docker container one by one."),(0,a.yg)("li",{parentName:"ol"},"SuperBench Executor gets return code and results of each benchmark once the benchmark finished."),(0,a.yg)("li",{parentName:"ol"},"SuperBench Executor sends the return code and results back to sb runner. SuperBench Runner Schecks return code and moves to the next execution."),(0,a.yg)("li",{parentName:"ol"},"Once all benchmarks finished, SuperBench Runner reduces results on all compute nodes, save log and results files, then summarize running results to SuperBench CLI."),(0,a.yg)("li",{parentName:"ol"},"SuperBench CLI returns the results to the user.")),(0,a.yg)("h2",{id:"components"},"Components"),(0,a.yg)("h3",{id:"superbench-cli"},"SuperBench CLI"),(0,a.yg)("p",null,"SuperBench CLI provides the command-line interface for users to use SuperBench and run related benchmarks.\nThe CLI provides a set of commands and corresponding help information to users."),(0,a.yg)("h3",{id:"superbench-runner"},"SuperBench Runner"),(0,a.yg)("p",null,"SuperBench Runner is the component to configure environments, prepare context, run benchmarks, collect log from nodes, and summarize results.\nIt controls the running logic, including when to start, which node or a set of nodes to run, whether a barrier is needed, etc.\nSuperBench Runner either communicates with host through SSH to configure running environments and prepare context,\nor talk with SuperBench Executor inside Docker container to execute benchmarks and collect log and results on each node."),(0,a.yg)("p",null,"Here're the details about work directory structure for SuperBench Runner."),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-bash"},"/path/to/working/directory\n\u2514\u2500\u2500 outputs/                                  # output root directory\n    \u2514\u2500\u2500 datetime                              # output directory name in %Y-%m-%d_%H-%M-%S format\n        \u251c\u2500\u2500 nodes                             # nodes directory\n        \u2502   \u2514\u2500\u2500 node-0                        # output collected from each node\n        \u2502       \u251c\u2500\u2500 benchmarks                # benchmarks directory\n        \u2502       \u2502   \u2514\u2500\u2500 benchmark-0           # output for each benchmark\n        \u2502       \u2502       \u2514\u2500\u2500 rank-0            # output for each rank in each benchmark\n        \u2502       \u2502           \u251c\u2500\u2500 results.json  # raw results\n        |       |           \u2514\u2500\u2500 monitor.jsonl # monitor results (optional)\n        |       \u251c\u2500\u2500 sb-bench.log              # SuperBench benchmarks' runtime log for debugging\n        \u2502       \u2514\u2500\u2500 sb-exec.log               # collected SuperBench Executor log\n        \u251c\u2500\u2500 sb-run.log                        # SuperBench Runner log\n        \u251c\u2500\u2500 sb.config.yaml                    # SuperBench configuration snapshot\n        \u251c\u2500\u2500 mpi_pattern.txt                   # generated host groups file under specified patterns in mpi mode (optional)\n        \u251c\u2500\u2500 ssh_config                        # generated SSH config file\n        \u251c\u2500\u2500 id_ed25519                        # generated SSH private key for each run\n        \u2514\u2500\u2500 id_ed25519.pub                    # generated SSH public key for each run\n")),(0,a.yg)("h3",{id:"superbench-executor"},"SuperBench Executor"),(0,a.yg)("p",null,"SuperBench Executor is the component to run benchmarks inside Docker container.\nIt will start the monitor (optional), execute each benchmark and handle all pre- and post-processing, including health check, result validation, result processing, etc."),(0,a.yg)("p",null,"Here're the SuperBench Executor's work directory structure inside Docker container.\nThe ",(0,a.yg)("inlineCode",{parentName:"p"},"/root")," directory is mounted from ",(0,a.yg)("inlineCode",{parentName:"p"},"$HOME/sb-workspace")," on the host path."),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-bash"},"/root\n\u251c\u2500\u2500 .ssh                              # SSH directory\n\u2502   \u251c\u2500\u2500 config                        # generated SSH config file\n\u2502   \u251c\u2500\u2500 id_ed25519                    # generated SSH private key from Runner\n\u2502   \u2514\u2500\u2500 id_ed25519.pub                # generated SSH public key from Runner\n\u2514\u2500\u2500 outputs/                          # output root directory\n    \u2514\u2500\u2500 datetime                      # output directory name in %Y-%m-%d_%H-%M-%S format\n        \u251c\u2500\u2500 benchmarks                # benchmarks directory\n        \u2502   \u2514\u2500\u2500 benchmark-0           # output for each benchmark\n        \u2502       \u2514\u2500\u2500 rank-0            # output for each rank in each benchmark\n        \u2502           \u251c\u2500\u2500 results.json  # raw results\n        \u2502           \u2514\u2500\u2500 monitor.jsonl # monitor results (optional)\n        \u251c\u2500\u2500 sb.config.yaml            # SuperBench configuration snapshot\n        \u251c\u2500\u2500 sb-bench.log              # SuperBench benchmarks' runtime log for debugging\n        \u2514\u2500\u2500 sb.env                    # SuperBench runtime environment variables\n")),(0,a.yg)("h3",{id:"benchmarks"},(0,a.yg)("a",{parentName:"h3",href:"/superbenchmark/docs/design-docs/benchmarks"},"Benchmarks")),(0,a.yg)("p",null,"Benchmarks are a set of tests that actually run on node to measure the hardware performance.\nHere're the related concepts, nccl benchmark is used as an example."),(0,a.yg)("ol",null,(0,a.yg)("li",{parentName:"ol"},(0,a.yg)("p",{parentName:"li"},"Module"),(0,a.yg)("p",{parentName:"li"},"One benchmark is one module, it has a set of abstract methods that should be implemented, e.g., pre check, measure, post check, save result, etc. The whole nccl benchmark is one module.")),(0,a.yg)("li",{parentName:"ol"},(0,a.yg)("p",{parentName:"li"},"Mode"),(0,a.yg)("p",{parentName:"li"},"One module may have several modes when running, each mode has corresponding method to run, e.g., local mode is running inside one node, mpi mode is running on all nodes but the command is only executed on one node, pair mode is running between two nodes for every combination, etc. The nccl module may have local mode and mpi mode.")),(0,a.yg)("li",{parentName:"ol"},(0,a.yg)("p",{parentName:"li"},"Task Group"),(0,a.yg)("p",{parentName:"li"},"One mode may have several task groups to run, each task group has a barrier when running. So only until the task group has finished on all nodes will the next task group start. The mpi mode of nccl module will run all reduce, all gather, etc., each should be treated as one task group.")),(0,a.yg)("li",{parentName:"ol"},(0,a.yg)("p",{parentName:"li"},"Task"),(0,a.yg)("p",{parentName:"li"},"One task group may contain several tasks to run, there's no barrier needed among these tasks inside one task group."))))}d.isMDXComponent=!0},2183:(e,n,r)=>{r.d(n,{A:()=>t});const t=r.p+"assets/images/executor-pipeline-07513bb43bae05c369d80eb52878bd6c.png"},7168:(e,n,r)=>{r.d(n,{A:()=>t});const t=r.p+"assets/images/executor_workflow-3879e2df373302843fefb214fc0c8e06.png"}}]);