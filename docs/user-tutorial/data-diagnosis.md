---
id: data-diagnosis
---

# Data Diagnosis

## Introduction

This tool is to filter the defective machines from thousands of benchmarking results automatically according to rules defined in **baseline file**.

## Input

The input mainly includes 2 files:

 - **raw data**: jsonl file including multiple nodes' results automatically generated by SuperBench runner.

    `Tips: the file can be found at ${output-dir}/results-summary.jsonl after each successful run.`

 - **baseline file**: It uses YAML format and includes each metrics' rules to filter defective servers for diagnosis.

### Baseline file

This section describes how to write rules in **baseline file**.

The convention is the same with [SuperBench Config File](https://microsoft.github.io/superbenchmark/docs/superbench-config), please view it first.

This baseline file describes the criteria and rules of the metrics used for data diagnosis. They are firstly organized by the benchmark name, and each benchmark includes several metrics or regex. One metric or regex should have criteria and a rule, which indicates that these metrics will use this rule to do the diagnosis.

Here is an overview of baseline file structure:

scheme:
```yaml
version: string
superbench:
  enable: string | [ string ]
  var:
    ${var_name}: dict
  benchmarks:
    ${benchmark_name}:
      enable: bool
      metrics:
        ${metric|regex}:
          criteria: number
          rules: dict
        ${metric|regex}:
          criteria: number
          rules: dict
        ...
```

example:
```yaml
# SuperBench baseline
version: v0.3
superbench:
  enable: null
  var:
    default_variance_rule: &default_variance_rule
      rules:
        name: variance
        condition: -0.05
    default_value_rule: &default_value_rule
      rules:
        name: value
    return_code_rule: &return_code_rule
      .*/return_code:
        criteria: 0
        <<: *default_value_rule
  benchmarks:
    kernel-launch:
        enable: true
        metrics:
          kernel-launch/event_overhead:\d+:
              criteria: 0.1
              rules:
                name: variance
                condition: 0.05
          kernel-launch/wall_overhead:\d+:
              criteria: 0.1
              rules:
                name: variance
                condition: 0.05
          <<: *return_code_rule
    mem-bw:
        enable: true
        metrics:
          mem-bw/H2D_Mem_BW:\d+:
              criteria: 25.6
              <<: *default_variance_rule
          <<: *return_code_rule
```

#### `metrics`

Metrics can be defined as either metric full name or regex for convenience.
Each benchmark used for diagnosis must contain a default rule for the metric `${benchmark_name}/return_code` as the above `&return_code_rule` in the example, which is used to identify failed tests.

#### `criteria`

The criteria number for the metric must be a numerical value.

#### `rules`

The rule is used to determine if the raw data meets the criteria for each metric.

2 types of rules are supported currently:

 `variance`:

   - `name`: variance
   - `condition`: the variance value between raw data and criteria. variance = (raw data - criteria) / criteria

  If the condition is positive, the rule is that the variance should be lower than the condition; if the condition is negative, the rule is that the variance should be larger than the condition.


  `value`:

  - `name`: value

  The rule is that the raw data should be smaller than the criteria.

## Output

We support different output formats for filtering the defective machines including jsonl, excel, etc. The output includes all defective servers' information including index, failure category, failure details, and detailed metrics.

- index: issued node name

- Category: benchmarks in which there is any metric violating the rules

- Issue Details: all violated metrics including metric data and related rule

- ${metric}: processed results of the metrics defined in the baseline file. If the rule is `variance`, the result of the metric is variance in percentage; if the rule is `value`, the result of the metric is raw data.
