{"SKU": "ND96isr_H100_v5", "GPU": "NVIDIA H100 SXM", "GPU_vendor": "NVIDIA", "Specifications":{"Number of GPUs": 8,"GPU Memory": "80GB per GPU","GPU Memory Bandwidth": "3.35TB/s","Interconnect": { "GPU to GPU": "900GB/s NVLink", "Host to GPU": "PCIe Gen5 128GB/s" }, "Computing Core Performance": {"FP64": "34 teraFLOPS", "FP64 Tensor Core": "67 teraFLOPS", "FP32": "67 teraFLOPS", "TF32 Tensor Core": "495 teraFLOPS", "BFLOAT16 Tensor Core": "989 teraFLOPS", "FP16 Tensor Core": "989 teraFLOPS", "FP8 Tensor Core": "1979 teraFLOPS", "INT8 Tensor Core": "1979 TOPS"}, "Infiniband Interconnect": "8x 400GB/s HDR100", "CPU": "xxx", "Disk":"xxx", "Decoders": "7 NVDEC 7 JPEG", "Max thermal design power (TDP)": "Up to 700W (configurable)", "Multi-instance GPUs": "Up to 7 MIGs @ 10GB each"}}
{"SKU": "nd96asr_v4", "GPU": "A100 40GB SXM", "GPU_vendor": "NVIDIA", "Specifications": {"Number of GPUs": 8, "GPU Memory": "40GB HBM2e", "Computing Core Performance": {"FP64": " 9.7 TFLOPS", "FP64 Tensor Core": "19.5 TFLOPS", "FP32": "19.5 TFLOPS", "Tensor Float 32 (TF32)": "156 TFLOPS", "BFLOAT16 Tensor Core": "312 TFLOPS", "FP16 Tensor Core": "312 TFLOPS", "INT8 Tensor Core": "624 TOPS"}, "GPU Memory Bandwidth": "1555 GB/s", "Max Thermal Design Power (TDP)": "400W", "Multi-Instance GPU": "Up to 7 MIGs @ 5GB", "Form Factor": "SXM", "Interconnect": {"GPU to GPU": "NVLink: 600 GB/s", "Host to GPU":  "Gen4:  PCIe 64 GB/s"}, "Infiniband Interconnect": "8x 200GB/s", "CPU": "xxx", "Disk":"xxx"}}
{"SKU": "nd96amsr_a100_v4", "GPU": "A100 80GB SXM", "GPU_vendor": "NVIDIA", "Specifications": {"CPU": "xxx", "Disk":"xxx", "Number of GPUs": 8, "GPU Memory": "80GB HBM2e", "Computing Core Performance": {"FP64": " 9.7 TFLOPS", "FP64 Tensor Core": "19.5 TFLOPS", "FP32": "19.5 TFLOPS", "Tensor Float 32 (TF32)": "156 TFLOPS", "BFLOAT16 Tensor Core": "312 TFLOPS", "FP16 Tensor Core": "312 TFLOPS", "INT8 Tensor Core": "624 TOPS TOPS"}, "GPU Memory Bandwidth": "2039 GB/s", "Max Thermal Design Power (TDP)": "400W", "Multi-Instance GPU": "Up to 7 MIGs @ 10GB", "Form Factor": "SXM", "Interconnect": {"GPU to GPU": "NVLink: 600 GB/s", "Host to GPU":  " PCIe Gen4: 64 GB/s"}, "Infiniband Interconnect": "8x 200GB/s"}}
{"SKU": "nd96ams_a100_v4", "GPU": "A100 80GB SXM", "GPU_vendor": "NVIDIA", "Specifications": {"Number of GPUs": 8, "GPU Memory": "80GB HBM2e", "Computing Core Performance": {"FP64": " 9.7 TFLOPS", "FP64 Tensor Core": "19.5 TFLOPS", "FP32": "19.5 TFLOPS", "Tensor Float 32 (TF32)": "156 TFLOPS", "BFLOAT16 Tensor Core": "312 TFLOPS", "FP16 Tensor Core": "312 TFLOPS", "INT8 Tensor Core": "624 TOPS"}, "GPU Memory Bandwidth": "2039 GB/s", "Max Thermal Design Power (TDP)": "400W", "Multi-Instance GPU": "Up to 7 MIGs @ 10GB", "Form Factor": "SXM", "Interconnect": {"GPU to GPU": "NVLink: 600 GB/s", "Host to GPU":  " PCIe Gen4: 64 GB/s"}, "Infiniband Interconnect": "no Infiniband", "CPU": "xxx", "Disk":"xxx"}}
{"SKU": "nd96asr_mi200_v4", "GPU": "AMD MI250", "GPU_vendor": "AMD", "Specifications": {"GPU Memory": {"Dedicated Memory Size": "128 GB", "Dedicated Memory Type": "HBM2e", "Memory Interface": "8192-bit", "Memory Clock": "1.6 GHz", "Peak Memory Bandwidth": "Up to 3276.8 GB/s", "Memory ECC Support": "Yes (Full-Chip)"}, "Computing Core Performance": {"Peak Half Precision (FP16) Performance": "362.1 TFLOPs", "Peak Engine Clock": "1700 MHz", "Peak Single Precision Matrix (FP32) Performance": "90.5 TFLOPs", "Peak Double Precision Matrix (FP64) Performance": "90.5 TFLOPs", "Peak Single Precision (FP32) Performance": "45.3 TFLOPs", "Peak Double Precision (FP64) Performance": "45.3 TFLOPs", "Peak INT4 Performance": "362.1 TOPs", "Peak INT8 Performance": "362.1 TOPs", "Peak bfloat16": "362.1 TFLOPs"}, "Interconnect": {"GPU to GPU": "Infinity Fabric™ Links*8 800GB/s", "Host to GPU":  "PCIe® 4.0 x16 64GB/s"}, "OS Support": "Linux x86_64", "GPU Architecture": "CDNA2", "Lithography": "TSMC 6nm FinFET", "Stream Processors": 13312, "Compute Units": 208, "Requirements": {"Total Board Power (TBP)": "500W | 560W Peak"},    "Board Specifications": {"Form Factor": "OAM Module",  "Cooling": "Passive OAM", "Additional Features": {"RAS Support": "Yes", "Page Retirement": "Yes", "Coherency Enabled": "No"}}}}
{"SKU": "AMD MI300x A1 BM or VM", "GPU_vendor": "AMD", "GPU": "AMD MI300x", "Specifications": {"Number of GPUs": 8, "GPU Memory": "192GB per GPU", "GPU Memory Bandwidth": "5.2TB/s", "Interconnect": {"GPU to GPU": "896GB/s Infinity Fabric", "Host to GPU":  "PCIe® 4.0 x16 64GB/s"}, "Computing Core Performance": {"TF32": "312TFLOPS", "FP16": "633TFLOPS", "FP8": "1151TFLOPS", "INT8":"1313TFLOPS", "BF16":"633", "FP64":"50TFLOPS", "FP32":"113TFLOPS"}, "Infiniband Interconnect": "50GB/s"}}
{"SKU": "AMD MI300x A0 BM or VM", "GPU_vendor": "AMD", "GPU": "AMD MI300x", "Specifications": {"Number of GPUs": 8, "GPU Memory": "192GB per GPU", "GPU Memory Bandwidth": "5.2TB/s", "Interconnect": {"GPU to GPU": "896GB/s Infinity Fabric", "Host to GPU":  "PCIe® 4.0 x16 64GB/s"}, "Computing Core Performance": {"TF32": "312TFLOPS", "FP16": "633TFLOPS", "FP8": "1151TFLOPS", "INT8":"1313TFLOPS", "BF16":"633", "FP64":"50TFLOPS", "FP32":"113TFLOPS"}, "Infiniband Interconnect": "50GB/s"}}
